{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EVA_ASSIGNMENT_20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "558px",
        "left": "1002px",
        "right": "20px",
        "top": "120px",
        "width": "315px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dWLrShClvj-v",
        "outputId": "bce3cb7e-9686-4ccd-d1dc-de15810dea5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!pip3 install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-emjxh_h2\n",
            "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-emjxh_h2\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from image-classifiers==1.0.0) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.17.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.12.0)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-cp36-none-any.whl size=19950 sha256=f4448db35ea384b32244bef38645dff8b50132ed990fb4e508076ad59a0d3cf3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gw3t43ex/wheels/de/2b/fd/29a6d33edb8c28bc7d94e95ea1d39c9a218ac500a3cfb1b197\n",
            "Successfully built image-classifiers\n",
            "Installing collected packages: image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KJma-MtjwPJJ",
        "outputId": "9c9bdd42-477b-4320-e406-b1862faf97d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6XaB4JtWsAbb",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uoVQ_cRHAu8u",
        "outputId": "3c9690c6-a4d3-46fe-e06f-3281e363d075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "# for keras\n",
        "from classification_models.keras import Classifiers\n",
        "\n",
        "# for tensorflow.keras\n",
        "# from classification_models.tfkeras import Classifiers\n",
        "\n",
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "conv_base = ResNet18((128, 128, 3), weights='imagenet', include_top= False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000_no_top.h5\n",
            "44924928/44920640 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV9Qb-e55sBe",
        "colab_type": "code",
        "outputId": "8c3cda4d-4f8a-41cf-89ce-e82bc790774b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, 128, 128, 3)  9           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 134, 134, 3)  0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, 64, 64, 64)   9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, 64, 64, 64)   256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, 64, 64, 64)   0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, 32, 32, 64)   4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 64)   0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 64)   0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, 16, 16, 128)  73728       zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, 18, 18, 128)  0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, 16, 16, 128)  8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 128)  0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, 18, 18, 128)  0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 128)  0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, 16, 16, 128)  0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 128)  0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, 8, 8, 256)    294912      zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, 8, 8, 256)    32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 256)    0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 256)    0           stage3_unit2_conv2[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu1 (Activation) (None, 8, 8, 256)    0           stage4_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 256)  0           stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv1 (Conv2D)     (None, 4, 4, 512)    1179648     zero_padding2d_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_16 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_sc (Conv2D)        (None, 4, 4, 512)    131072      stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 512)    0           stage4_unit1_conv2[0][0]         \n",
            "                                                                 stage4_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_17 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_18 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 512)    0           stage4_unit2_conv2[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, 4, 4, 512)    2048        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, 4, 4, 512)    0           bn1[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 11,186,889\n",
            "Trainable params: 11,178,947\n",
            "Non-trainable params: 7,942\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4SYw1_v7sCmS",
        "outputId": "f30d9ab6-a1ce-4ce2-f106-731a71f4df0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load cifar using the load data function\n",
        "# The data is in the shape of (Batch_size, num_channel, width, height)\n",
        "# np.unique returns unique class names\n",
        "\n",
        "(train_features, train_labels), (test_features, test_labels) =  keras.datasets.cifar10.load_data()\n",
        "num_train, img_rows, img_cols, img_channels =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))\n",
        "print(num_classes)\n",
        "\n",
        "\n",
        "\n",
        "# # Visualization of some particular classes from the dataset\n",
        "# class_names = ['airplane','automobile','bird','cat','deer',\n",
        "#                'dog','frog','horse','ship','truck']\n",
        "# fig = plt.figure(figsize=(8,3))\n",
        "# for i in range(num_classes):\n",
        "#     ax = fig.add_subplot(2, 5,1 + i, xticks=[], yticks=[])\n",
        "#     # gets the all the position of a particular class\n",
        "#     idx = np.where(train_labels[:]==i)[0]\n",
        "#     # using the idx we can find the corresponding image arrays\n",
        "#     features_idx = train_features[idx,::]\n",
        "#     # selects an img num by random\n",
        "#     img_num = np.random.randint(features_idx.shape[0])\n",
        "#     # gets the img array by img num\n",
        "#     im = features_idx[img_num]\n",
        "#     ax.set_title(class_names[i])\n",
        "#     plt.imshow(im)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8JIWfPRh0lrO",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "def resize_data(data):\n",
        "    data_upscaled = []\n",
        "    for i, img in enumerate(data):\n",
        "        large_img = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n",
        "        data_upscaled.append(large_img)\n",
        "    return np.array(data_upscaled)\n",
        "\n",
        "# resize train and  test data\n",
        "train_features = resize_data(train_features)\n",
        "test_features = resize_data(test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XunNlnNCCxBF",
        "outputId": "6fe0c255-58f9-43c0-b7af-2d0066711ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FoJMQWfXsE0a",
        "colab": {}
      },
      "source": [
        "# Normalize data\n",
        "train_features = preprocess_input(train_features)\n",
        "test_features = preprocess_input(test_features)\n",
        "# Convert class labels to binary class labels\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5neLm3A6OdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean = [0.4914, 0.4822, 0.4465]\n",
        "# std = [0.2023, 0.1994, 0.2010]\n",
        "# train_features = train_features - mean\n",
        "# train_features = train_features / std "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-5UNL_KmZgp",
        "colab_type": "code",
        "outputId": "e601c0d4-dfde-4f29-f335-32dd3d202f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C48nMkBp5sBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code is used from https://github.com/yu4u/cutout-random-erasing/blob/master/random_eraser.py\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    \n",
        "    # def norm_data(input_img):\n",
        "    #   input_img = input_img - mean\n",
        "    #   input_img = input_img / std\n",
        "    #   return input_img\n",
        "    \n",
        "\n",
        "    def eraser(input_img):\n",
        "        # input_img = norm_data(input_img)\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser\n",
        "\n",
        "class LR_Finder(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, start_lr=1e-5, end_lr=10, step_size=None, beta=.98):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.start_lr = start_lr\n",
        "        self.end_lr = end_lr\n",
        "        self.step_size = step_size\n",
        "        self.beta = beta\n",
        "        self.lr_mult = (end_lr/start_lr)**(1/step_size)\n",
        "        \n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.best_loss = 1e9\n",
        "        self.avg_loss = 0\n",
        "        self.losses, self.smoothed_losses, self.lrs, self.iterations = [], [], [], []\n",
        "        self.iteration = 0\n",
        "        logs = logs or {}\n",
        "        K.set_value(self.model.optimizer.lr, self.start_lr)\n",
        "        \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        loss = logs.get('loss')\n",
        "        self.iteration += 1\n",
        "        \n",
        "        self.avg_loss = self.beta * self.avg_loss + (1 - self.beta) * loss\n",
        "        smoothed_loss = self.avg_loss / (1 - self.beta**self.iteration)\n",
        "        \n",
        "        # Check if the loss is not exploding\n",
        "        if self.iteration>1 and smoothed_loss > self.best_loss * 4:\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        if smoothed_loss < self.best_loss or self.iteration==1:\n",
        "            self.best_loss = smoothed_loss\n",
        "        \n",
        "        lr = self.start_lr * (self.lr_mult**self.iteration)\n",
        "        \n",
        "        self.losses.append(loss)\n",
        "        self.smoothed_losses.append(smoothed_loss)\n",
        "        self.lrs.append(lr)\n",
        "        self.iterations.append(self.iteration)\n",
        "        \n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, lr)  \n",
        "        \n",
        "    def plot_lr(self):\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('Learning rate')\n",
        "        plt.plot(self.iterations, self.lrs)\n",
        "        \n",
        "    def plot(self, n_skip=10):\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Learning rate (log scale)')\n",
        "        plt.plot(self.lrs[n_skip:-5], self.losses[n_skip:-5])\n",
        "        plt.xscale('log')\n",
        "        \n",
        "    def plot_smoothed_loss(self, n_skip=10):\n",
        "        plt.ylabel('Smoothed Losses')\n",
        "        plt.xlabel('Learning rate (log scale)')\n",
        "        plt.plot(self.lrs[n_skip:-5], self.smoothed_losses[n_skip:-5])\n",
        "        plt.xscale('log')\n",
        "        \n",
        "    def plot_loss(self):\n",
        "        plt.ylabel('Losses')\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.plot(self.iterations[10:], self.losses[10:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w5h4Jvs5sB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create datagenerate for trainingtrain_batches\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=True,preprocessing_function=get_random_eraser(v_l=0.1, v_h=0.3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GW5n7OKbtWKE",
        "colab": {}
      },
      "source": [
        "# input_tensor = keras.layers.Input((32,32,3))\n",
        "# x = keras.layers.UpSampling2D()(input_tensor)\n",
        "# x = keras.layers.UpSampling2D()(x)\n",
        "# x = keras.layers.UpSampling2D()(x)\n",
        "# x = conv_base(conv_base.output)\n",
        "x = keras.layers.Conv2D(10,1)(conv_base.output)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Activation(tf.nn.softmax)(x)\n",
        "model = keras.models.Model(conv_base.input,x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWiEcRPj5sB7",
        "colab_type": "code",
        "outputId": "995ed526-7e94-4e48-bf5d-213d83747121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, 128, 128, 3)  9           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 134, 134, 3)  0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, 64, 64, 64)   9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, 64, 64, 64)   256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, 64, 64, 64)   0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, 32, 32, 64)   4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 64)   0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 64)   0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, 16, 16, 128)  73728       zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, 18, 18, 128)  0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, 16, 16, 128)  8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 128)  0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, 18, 18, 128)  0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 128)  0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, 16, 16, 128)  0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 128)  0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, 8, 8, 256)    294912      zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, 8, 8, 256)    32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 256)    0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 256)    0           stage3_unit2_conv2[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu1 (Activation) (None, 8, 8, 256)    0           stage4_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 256)  0           stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv1 (Conv2D)     (None, 4, 4, 512)    1179648     zero_padding2d_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_16 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_sc (Conv2D)        (None, 4, 4, 512)    131072      stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 512)    0           stage4_unit1_conv2[0][0]         \n",
            "                                                                 stage4_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_17 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_18 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 512)    0           stage4_unit2_conv2[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, 4, 4, 512)    2048        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, 4, 4, 512)    0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 4, 4, 10)     5130        relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 10)           0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 10)           0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 11,192,019\n",
            "Trainable params: 11,184,077\n",
            "Non-trainable params: 7,942\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BBIut4K9w7rz",
        "colab": {}
      },
      "source": [
        "################### Define the callbacks ###################\n",
        "\n",
        "base_dir = '/content/drive/My Drive/EVA/Session20'\n",
        "\n",
        "\n",
        "if not (os.path.exists(os.path.join(base_dir, 'weights_pretrain'))):\n",
        "    os.mkdir(os.path.join(base_dir, 'weights_pretrain'))\n",
        "\n",
        "filepath = os.path.join('/content/drive/My Drive/EVA/Session20/weights_pretrain',\n",
        "                        'weights-improvement-best.hdf5')\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dlUAu3IPzAk0",
        "outputId": "efbac09e-79e7-4840-ad8a-309126d638c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ##################### freeze layers for pretrain #######\n",
        "for index,l in enumerate(model.layers):\n",
        "  if index <  86:\n",
        "    l.trainable = False\n",
        "  else:\n",
        "    l.trainable = True\n",
        "for index,l in enumerate(model.layers):\n",
        "  print(l.name,index,l.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data 0 False\n",
            "bn_data 1 False\n",
            "zero_padding2d_1 2 False\n",
            "conv0 3 False\n",
            "bn0 4 False\n",
            "relu0 5 False\n",
            "zero_padding2d_2 6 False\n",
            "pooling0 7 False\n",
            "stage1_unit1_bn1 8 False\n",
            "stage1_unit1_relu1 9 False\n",
            "zero_padding2d_3 10 False\n",
            "stage1_unit1_conv1 11 False\n",
            "stage1_unit1_bn2 12 False\n",
            "stage1_unit1_relu2 13 False\n",
            "zero_padding2d_4 14 False\n",
            "stage1_unit1_conv2 15 False\n",
            "stage1_unit1_sc 16 False\n",
            "add_1 17 False\n",
            "stage1_unit2_bn1 18 False\n",
            "stage1_unit2_relu1 19 False\n",
            "zero_padding2d_5 20 False\n",
            "stage1_unit2_conv1 21 False\n",
            "stage1_unit2_bn2 22 False\n",
            "stage1_unit2_relu2 23 False\n",
            "zero_padding2d_6 24 False\n",
            "stage1_unit2_conv2 25 False\n",
            "add_2 26 False\n",
            "stage2_unit1_bn1 27 False\n",
            "stage2_unit1_relu1 28 False\n",
            "zero_padding2d_7 29 False\n",
            "stage2_unit1_conv1 30 False\n",
            "stage2_unit1_bn2 31 False\n",
            "stage2_unit1_relu2 32 False\n",
            "zero_padding2d_8 33 False\n",
            "stage2_unit1_conv2 34 False\n",
            "stage2_unit1_sc 35 False\n",
            "add_3 36 False\n",
            "stage2_unit2_bn1 37 False\n",
            "stage2_unit2_relu1 38 False\n",
            "zero_padding2d_9 39 False\n",
            "stage2_unit2_conv1 40 False\n",
            "stage2_unit2_bn2 41 False\n",
            "stage2_unit2_relu2 42 False\n",
            "zero_padding2d_10 43 False\n",
            "stage2_unit2_conv2 44 False\n",
            "add_4 45 False\n",
            "stage3_unit1_bn1 46 False\n",
            "stage3_unit1_relu1 47 False\n",
            "zero_padding2d_11 48 False\n",
            "stage3_unit1_conv1 49 False\n",
            "stage3_unit1_bn2 50 False\n",
            "stage3_unit1_relu2 51 False\n",
            "zero_padding2d_12 52 False\n",
            "stage3_unit1_conv2 53 False\n",
            "stage3_unit1_sc 54 False\n",
            "add_5 55 False\n",
            "stage3_unit2_bn1 56 False\n",
            "stage3_unit2_relu1 57 False\n",
            "zero_padding2d_13 58 False\n",
            "stage3_unit2_conv1 59 False\n",
            "stage3_unit2_bn2 60 False\n",
            "stage3_unit2_relu2 61 False\n",
            "zero_padding2d_14 62 False\n",
            "stage3_unit2_conv2 63 False\n",
            "add_6 64 False\n",
            "stage4_unit1_bn1 65 False\n",
            "stage4_unit1_relu1 66 False\n",
            "zero_padding2d_15 67 False\n",
            "stage4_unit1_conv1 68 False\n",
            "stage4_unit1_bn2 69 False\n",
            "stage4_unit1_relu2 70 False\n",
            "zero_padding2d_16 71 False\n",
            "stage4_unit1_conv2 72 False\n",
            "stage4_unit1_sc 73 False\n",
            "add_7 74 False\n",
            "stage4_unit2_bn1 75 False\n",
            "stage4_unit2_relu1 76 False\n",
            "zero_padding2d_17 77 False\n",
            "stage4_unit2_conv1 78 False\n",
            "stage4_unit2_bn2 79 False\n",
            "stage4_unit2_relu2 80 False\n",
            "zero_padding2d_18 81 False\n",
            "stage4_unit2_conv2 82 False\n",
            "add_8 83 False\n",
            "bn1 84 False\n",
            "relu1 85 False\n",
            "conv2d_1 86 True\n",
            "global_average_pooling2d_1 87 True\n",
            "activation_1 88 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-rHRdmB5sCR",
        "colab_type": "code",
        "outputId": "ef5bd3a9-4cda-4659-96ff-c894e2bf15e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model.compile(optimizer = keras.optimizers.SGD(lr=.1, momentum=.9, decay=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DkYEo6o2yDwR",
        "outputId": "0e8d2f78-2be6-4769-8ba7-c714b68687a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "start = time.time()\n",
        "step_per_epoch_train = len(train_features) // 128\n",
        "step_per_epoch_validation = len(test_features) // 128\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128), epochs = 5,\n",
        "                                 steps_per_epoch = step_per_epoch_train,\n",
        "                                 validation_data = (test_features, test_labels), verbose=1,\n",
        "                                 validation_steps = step_per_epoch_validation,\n",
        "                                 callbacks = [checkpoint])\n",
        "end = time.time()\n",
        "\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/5\n",
            "390/390 [==============================] - 21s 54ms/step - loss: 1.5056 - acc: 0.6310 - val_loss: 1.4750 - val_acc: 0.6912\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69120, saving model to /content/drive/My Drive/EVA/Session20/weights_pretrain/weights-improvement-best.hdf5\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 18s 47ms/step - loss: 0.9597 - acc: 0.6831 - val_loss: 1.0157 - val_acc: 0.7343\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69120 to 0.73430, saving model to /content/drive/My Drive/EVA/Session20/weights_pretrain/weights-improvement-best.hdf5\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 18s 47ms/step - loss: 0.8826 - acc: 0.6956 - val_loss: 1.1280 - val_acc: 0.7120\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.73430\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 18s 47ms/step - loss: 0.8556 - acc: 0.7020 - val_loss: 0.9725 - val_acc: 0.7393\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.73430 to 0.73930, saving model to /content/drive/My Drive/EVA/Session20/weights_pretrain/weights-improvement-best.hdf5\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 19s 48ms/step - loss: 0.8362 - acc: 0.7098 - val_loss: 1.0061 - val_acc: 0.7379\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.73930\n",
            "Model took 100.85 seconds to train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qDM-u1xeSW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pretrain model to do finetuning\n",
        "model = keras.models.load_model('/content/drive/My Drive/EVA/Session20/weights_pretrain/weights-improvement-best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwoCKO5A5sCa",
        "colab_type": "code",
        "outputId": "c8ecd405-c0f7-4074-d753-640b3f6806bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index,l in enumerate(model.layers):\n",
        "  if index <  46:\n",
        "    l.trainable = False\n",
        "  else:\n",
        "    l.trainable = True\n",
        "for index,l in enumerate(model.layers):\n",
        "  print(l.name,index,l.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data 0 False\n",
            "bn_data 1 False\n",
            "zero_padding2d_1 2 False\n",
            "conv0 3 False\n",
            "bn0 4 False\n",
            "relu0 5 False\n",
            "zero_padding2d_2 6 False\n",
            "pooling0 7 False\n",
            "stage1_unit1_bn1 8 False\n",
            "stage1_unit1_relu1 9 False\n",
            "zero_padding2d_3 10 False\n",
            "stage1_unit1_conv1 11 False\n",
            "stage1_unit1_bn2 12 False\n",
            "stage1_unit1_relu2 13 False\n",
            "zero_padding2d_4 14 False\n",
            "stage1_unit1_conv2 15 False\n",
            "stage1_unit1_sc 16 False\n",
            "add_1 17 False\n",
            "stage1_unit2_bn1 18 False\n",
            "stage1_unit2_relu1 19 False\n",
            "zero_padding2d_5 20 False\n",
            "stage1_unit2_conv1 21 False\n",
            "stage1_unit2_bn2 22 False\n",
            "stage1_unit2_relu2 23 False\n",
            "zero_padding2d_6 24 False\n",
            "stage1_unit2_conv2 25 False\n",
            "add_2 26 False\n",
            "stage2_unit1_bn1 27 False\n",
            "stage2_unit1_relu1 28 False\n",
            "zero_padding2d_7 29 False\n",
            "stage2_unit1_conv1 30 False\n",
            "stage2_unit1_bn2 31 False\n",
            "stage2_unit1_relu2 32 False\n",
            "zero_padding2d_8 33 False\n",
            "stage2_unit1_conv2 34 False\n",
            "stage2_unit1_sc 35 False\n",
            "add_3 36 False\n",
            "stage2_unit2_bn1 37 False\n",
            "stage2_unit2_relu1 38 False\n",
            "zero_padding2d_9 39 False\n",
            "stage2_unit2_conv1 40 False\n",
            "stage2_unit2_bn2 41 False\n",
            "stage2_unit2_relu2 42 False\n",
            "zero_padding2d_10 43 False\n",
            "stage2_unit2_conv2 44 False\n",
            "add_4 45 False\n",
            "stage3_unit1_bn1 46 True\n",
            "stage3_unit1_relu1 47 True\n",
            "zero_padding2d_11 48 True\n",
            "stage3_unit1_conv1 49 True\n",
            "stage3_unit1_bn2 50 True\n",
            "stage3_unit1_relu2 51 True\n",
            "zero_padding2d_12 52 True\n",
            "stage3_unit1_conv2 53 True\n",
            "stage3_unit1_sc 54 True\n",
            "add_5 55 True\n",
            "stage3_unit2_bn1 56 True\n",
            "stage3_unit2_relu1 57 True\n",
            "zero_padding2d_13 58 True\n",
            "stage3_unit2_conv1 59 True\n",
            "stage3_unit2_bn2 60 True\n",
            "stage3_unit2_relu2 61 True\n",
            "zero_padding2d_14 62 True\n",
            "stage3_unit2_conv2 63 True\n",
            "add_6 64 True\n",
            "stage4_unit1_bn1 65 True\n",
            "stage4_unit1_relu1 66 True\n",
            "zero_padding2d_15 67 True\n",
            "stage4_unit1_conv1 68 True\n",
            "stage4_unit1_bn2 69 True\n",
            "stage4_unit1_relu2 70 True\n",
            "zero_padding2d_16 71 True\n",
            "stage4_unit1_conv2 72 True\n",
            "stage4_unit1_sc 73 True\n",
            "add_7 74 True\n",
            "stage4_unit2_bn1 75 True\n",
            "stage4_unit2_relu1 76 True\n",
            "zero_padding2d_17 77 True\n",
            "stage4_unit2_conv1 78 True\n",
            "stage4_unit2_bn2 79 True\n",
            "stage4_unit2_relu2 80 True\n",
            "zero_padding2d_18 81 True\n",
            "stage4_unit2_conv2 82 True\n",
            "add_8 83 True\n",
            "bn1 84 True\n",
            "relu1 85 True\n",
            "conv2d_1 86 True\n",
            "global_average_pooling2d_1 87 True\n",
            "activation_1 88 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fQ0jsL75sCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################### Define the callbacks ###################\n",
        "\n",
        "base_dir = '/content/drive/My Drive/EVA/Session20'\n",
        "\n",
        "\n",
        "if not (os.path.exists(os.path.join(base_dir, 'weights'))):\n",
        "    os.mkdir(os.path.join(base_dir, 'weights'))\n",
        "\n",
        "filepath = os.path.join('/content/drive/My Drive/EVA/Session20/weights',\n",
        "                        'weights-improvement-best.hdf5')\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='max')\n",
        "def scheduler(epoch, lr):\n",
        "    return round(lr * 1 / (1 + 0.050 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcvO1M9vhdjJ",
        "colab_type": "code",
        "outputId": "6ee244e8-1b32-487a-e12e-2fd7923b4808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVfKdrd_5sCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = keras.optimizers.SGD(lr=.1, momentum=.9, decay=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JGUbJ-UdCBdR",
        "outputId": "e1f87247-6013-4e5b-ef8f-3b479071b9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start = time.time()\n",
        "step_per_epoch_train = len(train_features) // 128\n",
        "step_per_epoch_validation = len(test_features) // 128\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128), epochs = 50,\n",
        "                                 steps_per_epoch = step_per_epoch_train,\n",
        "                                 validation_data = (test_features, test_labels), verbose=1,\n",
        "                                 validation_steps = step_per_epoch_validation,\n",
        "                                callbacks=[LearningRateScheduler(scheduler, verbose=1),checkpoint])\n",
        "end = time.time()\n",
        "\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.1000000015.\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 0.9222 - acc: 0.7060 - val_loss: 1.0393 - val_acc: 0.6903\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69030, saving model to /content/drive/My Drive/EVA/Session20/weights/weights-improvement-best.hdf5\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0952380967.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.4914 - acc: 0.8319 - val_loss: 0.5766 - val_acc: 0.8071\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69030 to 0.80710, saving model to /content/drive/My Drive/EVA/Session20/weights/weights-improvement-best.hdf5\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0865800882.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.3724 - acc: 0.8708 - val_loss: 0.7345 - val_acc: 0.7861\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80710\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.075287035.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.3102 - acc: 0.8929 - val_loss: 0.6898 - val_acc: 0.8003\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80710\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0627391972.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.2577 - acc: 0.9102 - val_loss: 0.5878 - val_acc: 0.8256\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.80710 to 0.82560, saving model to /content/drive/My Drive/EVA/Session20/weights/weights-improvement-best.hdf5\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0501913607.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.2139 - acc: 0.9252 - val_loss: 1.0506 - val_acc: 0.7387\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.82560\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0386087396.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1875 - acc: 0.9344 - val_loss: 0.8292 - val_acc: 0.7910\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.82560\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0285990674.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1615 - acc: 0.9438 - val_loss: 0.6796 - val_acc: 0.8204\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.82560\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0204279048.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1477 - acc: 0.9490 - val_loss: 0.6329 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.82560 to 0.83560, saving model to /content/drive/My Drive/EVA/Session20/weights/weights-improvement-best.hdf5\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0140882104.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1388 - acc: 0.9521 - val_loss: 0.6430 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.83560\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0093921404.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1350 - acc: 0.9536 - val_loss: 0.6430 - val_acc: 0.8363\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.83560 to 0.83630, saving model to /content/drive/My Drive/EVA/Session20/weights/weights-improvement-best.hdf5\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0060594454.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1281 - acc: 0.9550 - val_loss: 0.6070 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.83630 to 0.84360, saving model to /content/drive/My Drive/EVA/Session20/weights/weights-improvement-best.hdf5\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0037871534.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1249 - acc: 0.9563 - val_loss: 0.6313 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.84360\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0022952445.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1244 - acc: 0.9567 - val_loss: 0.6272 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.84360\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0013501438.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1220 - acc: 0.9593 - val_loss: 0.6434 - val_acc: 0.8403\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.84360\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0007715107.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1204 - acc: 0.9585 - val_loss: 0.6302 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.84360\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0004286171.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1196 - acc: 0.9586 - val_loss: 0.6348 - val_acc: 0.8413\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.84360\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0002316849.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1238 - acc: 0.9578 - val_loss: 0.6327 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.84360\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001219394.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1228 - acc: 0.9583 - val_loss: 0.6326 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.84360\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 6.2533e-05.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1214 - acc: 0.9585 - val_loss: 0.6300 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.84360\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 3.12665e-05.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1243 - acc: 0.9575 - val_loss: 0.6365 - val_acc: 0.8412\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.84360\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 1.5252e-05.\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.1191 - acc: 0.9592 - val_loss: 0.6341 - val_acc: 0.8420\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.84360\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 7.2629e-06.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1215 - acc: 0.9582 - val_loss: 0.6335 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.84360\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 3.3781e-06.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1231 - acc: 0.9571 - val_loss: 0.6423 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.84360\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 1.5355e-06.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1229 - acc: 0.9584 - val_loss: 0.6309 - val_acc: 0.8425\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.84360\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 6.824e-07.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1193 - acc: 0.9588 - val_loss: 0.6295 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.84360\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 2.967e-07.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1255 - acc: 0.9577 - val_loss: 0.6270 - val_acc: 0.8432\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.84360\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 1.263e-07.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1203 - acc: 0.9583 - val_loss: 0.6277 - val_acc: 0.8420\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.84360\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 5.26e-08.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1208 - acc: 0.9586 - val_loss: 0.6373 - val_acc: 0.8422\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.84360\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 2.15e-08.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1186 - acc: 0.9580 - val_loss: 0.6313 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.84360\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 8.6e-09.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1237 - acc: 0.9581 - val_loss: 0.6420 - val_acc: 0.8411\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.84360\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 3.4e-09.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1201 - acc: 0.9595 - val_loss: 0.6358 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.84360\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 1.3e-09.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1201 - acc: 0.9588 - val_loss: 0.6254 - val_acc: 0.8424\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.84360\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 5e-10.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1184 - acc: 0.9587 - val_loss: 0.6321 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.84360\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 2e-10.\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.1212 - acc: 0.9582 - val_loss: 0.6334 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.84360\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 1e-10.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1214 - acc: 0.9586 - val_loss: 0.6357 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.84360\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1201 - acc: 0.9591 - val_loss: 0.6371 - val_acc: 0.8412\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.84360\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1225 - acc: 0.9581 - val_loss: 0.6328 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.84360\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1204 - acc: 0.9585 - val_loss: 0.6283 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.84360\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1200 - acc: 0.9580 - val_loss: 0.6337 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.84360\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1207 - acc: 0.9587 - val_loss: 0.6379 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.84360\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1219 - acc: 0.9577 - val_loss: 0.6363 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.84360\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1245 - acc: 0.9571 - val_loss: 0.6321 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.84360\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1225 - acc: 0.9584 - val_loss: 0.6333 - val_acc: 0.8421\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.84360\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1197 - acc: 0.9593 - val_loss: 0.6367 - val_acc: 0.8412\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.84360\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1201 - acc: 0.9592 - val_loss: 0.6346 - val_acc: 0.8420\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.84360\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1213 - acc: 0.9573 - val_loss: 0.6318 - val_acc: 0.8420\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.84360\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1227 - acc: 0.9586 - val_loss: 0.6366 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.84360\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1196 - acc: 0.9578 - val_loss: 0.6345 - val_acc: 0.8417\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.84360\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0.\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.1230 - acc: 0.9576 - val_loss: 0.6339 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.84360\n",
            "Model took 1391.57 seconds to train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQuHFFbp5sCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model(\n",
        "    os.path.join('/content/drive/My Drive/EVA/Session20/weights/weights-improvement-best.hdf5'))\n",
        "score = model.evaluate(test_features, test_labels, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha8OnrEQn946",
        "colab_type": "code",
        "outputId": "a4825c58-529b-48e4-a779-566c3e67a051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6070131373941898, 0.8436]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfgRVsd2oHnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}